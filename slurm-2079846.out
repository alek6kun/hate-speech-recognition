Starting job on i46
Loading modules...

Lmod is automatically replacing "gcc/11.3.0" with "intel/2021.6.0".

Lmod has detected the following error: These module(s) or extension(s) exist
but cannot be loaded as requested: "py-torch/2.0.1-mpi-openmp-cuda",
"openmpi/4.1.3-cuda"
   Try: "module spider py-torch/2.0.1-mpi-openmp-cuda openmpi/4.1.3-cuda" to
see how to load the module(s).



Activating virtual environment...
Running Python script...
/home/limozin/venvs/course_py-3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using device: cuda
Epoch 1/3
Batch 4/887, Batch Loss: 0.1732
Batch 8/887, Batch Loss: 0.1753
Batch 12/887, Batch Loss: 0.1651
Batch 16/887, Batch Loss: 0.1710
Batch 20/887, Batch Loss: 0.1474
Batch 24/887, Batch Loss: 0.1495
Batch 28/887, Batch Loss: 0.1647
Batch 32/887, Batch Loss: 0.1532
Batch 36/887, Batch Loss: 0.1603
Batch 40/887, Batch Loss: 0.1418
Batch 44/887, Batch Loss: 0.1417
Batch 48/887, Batch Loss: 0.1441
Batch 52/887, Batch Loss: 0.1396
Batch 56/887, Batch Loss: 0.1870
Batch 60/887, Batch Loss: 0.1574
Batch 64/887, Batch Loss: 0.1672
Batch 68/887, Batch Loss: 0.1660
Batch 72/887, Batch Loss: 0.1479
Batch 76/887, Batch Loss: 0.1559
Batch 80/887, Batch Loss: 0.1389
Batch 84/887, Batch Loss: 0.1163
Batch 88/887, Batch Loss: 0.1350
Batch 92/887, Batch Loss: 0.1193
Batch 96/887, Batch Loss: 0.1090
Batch 100/887, Batch Loss: 0.1359
Batch 104/887, Batch Loss: 0.1391
Batch 108/887, Batch Loss: 0.1513
Batch 112/887, Batch Loss: 0.1447
Batch 116/887, Batch Loss: 0.1650
Batch 120/887, Batch Loss: 0.1685
Batch 124/887, Batch Loss: 0.0970
Batch 128/887, Batch Loss: 0.1551
Batch 132/887, Batch Loss: 0.1093
Batch 136/887, Batch Loss: 0.1471
Batch 140/887, Batch Loss: 0.1497
Batch 144/887, Batch Loss: 0.1184
Batch 148/887, Batch Loss: 0.1479
Batch 152/887, Batch Loss: 0.1474
Batch 156/887, Batch Loss: 0.1395
Batch 160/887, Batch Loss: 0.1835
Batch 164/887, Batch Loss: 0.1532
Batch 168/887, Batch Loss: 0.1240
Batch 172/887, Batch Loss: 0.1286
Batch 176/887, Batch Loss: 0.1654
Batch 180/887, Batch Loss: 0.1362
Batch 184/887, Batch Loss: 0.1304
Batch 188/887, Batch Loss: 0.1187
Batch 192/887, Batch Loss: 0.1538
Batch 196/887, Batch Loss: 0.1273
Batch 200/887, Batch Loss: 0.1413
Batch 204/887, Batch Loss: 0.1390
Batch 208/887, Batch Loss: 0.1402
Batch 212/887, Batch Loss: 0.1573
Batch 216/887, Batch Loss: 0.1463
Batch 220/887, Batch Loss: 0.1505
Batch 224/887, Batch Loss: 0.1277
Batch 228/887, Batch Loss: 0.1426
Batch 232/887, Batch Loss: 0.1291
Batch 236/887, Batch Loss: 0.1193
Batch 240/887, Batch Loss: 0.1368
Batch 244/887, Batch Loss: 0.1478
Batch 248/887, Batch Loss: 0.1735
Batch 252/887, Batch Loss: 0.1419
Batch 256/887, Batch Loss: 0.1551
Batch 260/887, Batch Loss: 0.1329
Batch 264/887, Batch Loss: 0.1158
Batch 268/887, Batch Loss: 0.1142
Batch 272/887, Batch Loss: 0.1151
Batch 276/887, Batch Loss: 0.1564
Batch 280/887, Batch Loss: 0.1723
Batch 284/887, Batch Loss: 0.1488
Batch 288/887, Batch Loss: 0.1579
Batch 292/887, Batch Loss: 0.1426
Batch 296/887, Batch Loss: 0.1423
Batch 300/887, Batch Loss: 0.1485
Batch 304/887, Batch Loss: 0.1245
Batch 308/887, Batch Loss: 0.1132
Batch 312/887, Batch Loss: 0.1474
Batch 316/887, Batch Loss: 0.1677
Batch 320/887, Batch Loss: 0.1453
Batch 324/887, Batch Loss: 0.1051
Batch 328/887, Batch Loss: 0.1369
Batch 332/887, Batch Loss: 0.1252
Batch 336/887, Batch Loss: 0.1461
Batch 340/887, Batch Loss: 0.1502
Batch 344/887, Batch Loss: 0.1273
Batch 348/887, Batch Loss: 0.1316
Batch 352/887, Batch Loss: 0.1389
Batch 356/887, Batch Loss: 0.1320
Batch 360/887, Batch Loss: 0.1061
Batch 364/887, Batch Loss: 0.1292
Batch 368/887, Batch Loss: 0.1289
Batch 372/887, Batch Loss: 0.1414
Batch 376/887, Batch Loss: 0.1246
Batch 380/887, Batch Loss: 0.1835
Batch 384/887, Batch Loss: 0.1268
Batch 388/887, Batch Loss: 0.1391
Batch 392/887, Batch Loss: 0.1528
Batch 396/887, Batch Loss: 0.1394
Batch 400/887, Batch Loss: 0.1015
Batch 404/887, Batch Loss: 0.0984
Batch 408/887, Batch Loss: 0.0963
Batch 412/887, Batch Loss: 0.1328
Batch 416/887, Batch Loss: 0.1169
Batch 420/887, Batch Loss: 0.1299
Batch 424/887, Batch Loss: 0.1445
Batch 428/887, Batch Loss: 0.1698
Batch 432/887, Batch Loss: 0.1585
Batch 436/887, Batch Loss: 0.1412
Batch 440/887, Batch Loss: 0.1283
Batch 444/887, Batch Loss: 0.1277
Batch 448/887, Batch Loss: 0.1023
Batch 452/887, Batch Loss: 0.1429
Batch 456/887, Batch Loss: 0.1751
Batch 460/887, Batch Loss: 0.1550
Batch 464/887, Batch Loss: 0.1369
Batch 468/887, Batch Loss: 0.1210
Batch 472/887, Batch Loss: 0.1229
Batch 476/887, Batch Loss: 0.1213
Batch 480/887, Batch Loss: 0.1114
Batch 484/887, Batch Loss: 0.1366
Batch 488/887, Batch Loss: 0.1506
Batch 492/887, Batch Loss: 0.1200
Batch 496/887, Batch Loss: 0.1111
Batch 500/887, Batch Loss: 0.1371
Batch 504/887, Batch Loss: 0.1359
Batch 508/887, Batch Loss: 0.1725
Batch 512/887, Batch Loss: 0.1178
Batch 516/887, Batch Loss: 0.1396
Batch 520/887, Batch Loss: 0.1624
Batch 524/887, Batch Loss: 0.1450
Batch 528/887, Batch Loss: 0.1411
Batch 532/887, Batch Loss: 0.1352
Batch 536/887, Batch Loss: 0.1216
Batch 540/887, Batch Loss: 0.1291
Batch 544/887, Batch Loss: 0.1233
Batch 548/887, Batch Loss: 0.1542
Batch 552/887, Batch Loss: 0.1614
Batch 556/887, Batch Loss: 0.1443
Batch 560/887, Batch Loss: 0.1305
Batch 564/887, Batch Loss: 0.1244
Batch 568/887, Batch Loss: 0.1222
Batch 572/887, Batch Loss: 0.1160
Batch 576/887, Batch Loss: 0.1404
Batch 580/887, Batch Loss: 0.0988
Batch 584/887, Batch Loss: 0.1385
Batch 588/887, Batch Loss: 0.1659
Batch 592/887, Batch Loss: 0.1363
Batch 596/887, Batch Loss: 0.1421
Batch 600/887, Batch Loss: 0.1379
Batch 604/887, Batch Loss: 0.1686
Batch 608/887, Batch Loss: 0.1291
Batch 612/887, Batch Loss: 0.1305
Batch 616/887, Batch Loss: 0.1369
Batch 620/887, Batch Loss: 0.1520
Batch 624/887, Batch Loss: 0.0924
Batch 628/887, Batch Loss: 0.1407
Batch 632/887, Batch Loss: 0.1442
Batch 636/887, Batch Loss: 0.1344
Batch 640/887, Batch Loss: 0.1370
Batch 644/887, Batch Loss: 0.1250
Batch 648/887, Batch Loss: 0.1444
Batch 652/887, Batch Loss: 0.1333
Batch 656/887, Batch Loss: 0.1345
Batch 660/887, Batch Loss: 0.1196
Batch 664/887, Batch Loss: 0.1266
Batch 668/887, Batch Loss: 0.1334
Batch 672/887, Batch Loss: 0.1035
Batch 676/887, Batch Loss: 0.1366
Batch 680/887, Batch Loss: 0.1388
Batch 684/887, Batch Loss: 0.1368
Batch 688/887, Batch Loss: 0.1167
Batch 692/887, Batch Loss: 0.1277
Batch 696/887, Batch Loss: 0.1099
Batch 700/887, Batch Loss: 0.0981
Batch 704/887, Batch Loss: 0.1526
Batch 708/887, Batch Loss: 0.1095
Batch 712/887, Batch Loss: 0.1002
Batch 716/887, Batch Loss: 0.1399
Batch 720/887, Batch Loss: 0.1194
Batch 724/887, Batch Loss: 0.1445
Batch 728/887, Batch Loss: 0.1264
Batch 732/887, Batch Loss: 0.1419
Batch 736/887, Batch Loss: 0.1189
Batch 740/887, Batch Loss: 0.1207
Batch 744/887, Batch Loss: 0.1102
Batch 748/887, Batch Loss: 0.1200
Batch 752/887, Batch Loss: 0.1674
Batch 756/887, Batch Loss: 0.1481
Batch 760/887, Batch Loss: 0.1467
Batch 764/887, Batch Loss: 0.1337
Batch 768/887, Batch Loss: 0.1273
Batch 772/887, Batch Loss: 0.1283
Batch 776/887, Batch Loss: 0.1219
Batch 780/887, Batch Loss: 0.1274
Batch 784/887, Batch Loss: 0.1330
Batch 788/887, Batch Loss: 0.1357
Batch 792/887, Batch Loss: 0.1361
Batch 796/887, Batch Loss: 0.1438
Batch 800/887, Batch Loss: 0.1295
Batch 804/887, Batch Loss: 0.1380
Batch 808/887, Batch Loss: 0.1474
Batch 812/887, Batch Loss: 0.1237
Batch 816/887, Batch Loss: 0.1290
Batch 820/887, Batch Loss: 0.1265
Batch 824/887, Batch Loss: 0.1243
Batch 828/887, Batch Loss: 0.1255
Batch 832/887, Batch Loss: 0.1393
Batch 836/887, Batch Loss: 0.1385
Batch 840/887, Batch Loss: 0.1535
Batch 844/887, Batch Loss: 0.1326
Batch 848/887, Batch Loss: 0.1460
Batch 852/887, Batch Loss: 0.1466
Batch 856/887, Batch Loss: 0.1187
Batch 860/887, Batch Loss: 0.1160
Batch 864/887, Batch Loss: 0.1229
Batch 868/887, Batch Loss: 0.1093
Batch 872/887, Batch Loss: 0.1427
Batch 876/887, Batch Loss: 0.1619
Batch 880/887, Batch Loss: 0.1206
Batch 884/887, Batch Loss: 0.1568
Training Loss: 0.1372
Validation Metrics: {'accuracy': 0.7436656794998354, 'precision': 0.9375, 'recall': 0.004792332268370607, 'f1': 0.009535918626827717}
Epoch 2/3
Batch 4/887, Batch Loss: 0.1560
Batch 8/887, Batch Loss: 0.1472
Batch 12/887, Batch Loss: 0.1086
Batch 16/887, Batch Loss: 0.1162
Batch 20/887, Batch Loss: 0.1238
Batch 24/887, Batch Loss: 0.1658
Batch 28/887, Batch Loss: 0.1675
Batch 32/887, Batch Loss: 0.1434
Batch 36/887, Batch Loss: 0.1183
Batch 40/887, Batch Loss: 0.1294
Batch 44/887, Batch Loss: 0.1300
Batch 48/887, Batch Loss: 0.1030
Batch 52/887, Batch Loss: 0.1315
Batch 56/887, Batch Loss: 0.1438
Batch 60/887, Batch Loss: 0.1481
Batch 64/887, Batch Loss: 0.1316
Batch 68/887, Batch Loss: 0.1360
Batch 72/887, Batch Loss: 0.1534
Batch 76/887, Batch Loss: 0.1262
Batch 80/887, Batch Loss: 0.1502
Batch 84/887, Batch Loss: 0.1112
Batch 88/887, Batch Loss: 0.0937
Batch 92/887, Batch Loss: 0.1459
Batch 96/887, Batch Loss: 0.1243
Batch 100/887, Batch Loss: 0.1697
Batch 104/887, Batch Loss: 0.0925
Batch 108/887, Batch Loss: 0.1156
Batch 112/887, Batch Loss: 0.1381
Batch 116/887, Batch Loss: 0.1481
Batch 120/887, Batch Loss: 0.1397
Batch 124/887, Batch Loss: 0.1247
Batch 128/887, Batch Loss: 0.1377
Batch 132/887, Batch Loss: 0.1321
Batch 136/887, Batch Loss: 0.1151
Batch 140/887, Batch Loss: 0.1583
Batch 144/887, Batch Loss: 0.1424
Batch 148/887, Batch Loss: 0.1298
Batch 152/887, Batch Loss: 0.1368
Batch 156/887, Batch Loss: 0.1091
Batch 160/887, Batch Loss: 0.1300
Batch 164/887, Batch Loss: 0.1160
Batch 168/887, Batch Loss: 0.0890
Batch 172/887, Batch Loss: 0.1163
Batch 176/887, Batch Loss: 0.1298
Batch 180/887, Batch Loss: 0.1553
Batch 184/887, Batch Loss: 0.1438
Batch 188/887, Batch Loss: 0.1194
Batch 192/887, Batch Loss: 0.0965
Batch 196/887, Batch Loss: 0.1249
Batch 200/887, Batch Loss: 0.2208
Batch 204/887, Batch Loss: 0.1189
Batch 208/887, Batch Loss: 0.0794
Batch 212/887, Batch Loss: 0.1048
Batch 216/887, Batch Loss: 0.1352
Batch 220/887, Batch Loss: 0.1299
Batch 224/887, Batch Loss: 0.1447
Batch 228/887, Batch Loss: 0.1423
Batch 232/887, Batch Loss: 0.1491
Batch 236/887, Batch Loss: 0.1205
Batch 240/887, Batch Loss: 0.1288
Batch 244/887, Batch Loss: 0.1475
Batch 248/887, Batch Loss: 0.1316
Batch 252/887, Batch Loss: 0.1077
Batch 256/887, Batch Loss: 0.1581
Batch 260/887, Batch Loss: 0.1420
Batch 264/887, Batch Loss: 0.1270
Batch 268/887, Batch Loss: 0.1159
Batch 272/887, Batch Loss: 0.1685
Batch 276/887, Batch Loss: 0.1425
Batch 280/887, Batch Loss: 0.1334
Batch 284/887, Batch Loss: 0.1256
Batch 288/887, Batch Loss: 0.1630
Batch 292/887, Batch Loss: 0.1434
Batch 296/887, Batch Loss: 0.1372
Batch 300/887, Batch Loss: 0.1353
Batch 304/887, Batch Loss: 0.1457
Batch 308/887, Batch Loss: 0.1366
Batch 312/887, Batch Loss: 0.1127
Batch 316/887, Batch Loss: 0.1279
Batch 320/887, Batch Loss: 0.1309
Batch 324/887, Batch Loss: 0.1424
Batch 328/887, Batch Loss: 0.1168
Batch 332/887, Batch Loss: 0.1340
Batch 336/887, Batch Loss: 0.1299
Batch 340/887, Batch Loss: 0.1381
Batch 344/887, Batch Loss: 0.1645
Batch 348/887, Batch Loss: 0.1490
Batch 352/887, Batch Loss: 0.1189
Batch 356/887, Batch Loss: 0.1235
Batch 360/887, Batch Loss: 0.1471
Batch 364/887, Batch Loss: 0.1098
Batch 368/887, Batch Loss: 0.1288
Batch 372/887, Batch Loss: 0.1376
Batch 376/887, Batch Loss: 0.1387
Batch 380/887, Batch Loss: 0.1406
Batch 384/887, Batch Loss: 0.1261
Batch 388/887, Batch Loss: 0.1258
Batch 392/887, Batch Loss: 0.1216
Batch 396/887, Batch Loss: 0.1367
Batch 400/887, Batch Loss: 0.1466
Batch 404/887, Batch Loss: 0.1265
Batch 408/887, Batch Loss: 0.1081
Batch 412/887, Batch Loss: 0.1428
Batch 416/887, Batch Loss: 0.1553
Batch 420/887, Batch Loss: 0.1161
Batch 424/887, Batch Loss: 0.1282
Batch 428/887, Batch Loss: 0.1371
Batch 432/887, Batch Loss: 0.1877
Batch 436/887, Batch Loss: 0.1182
Batch 440/887, Batch Loss: 0.1387
Batch 444/887, Batch Loss: 0.1393
Batch 448/887, Batch Loss: 0.1332
Batch 452/887, Batch Loss: 0.1247
Batch 456/887, Batch Loss: 0.1102
Batch 460/887, Batch Loss: 0.1100
Batch 464/887, Batch Loss: 0.1100
Batch 468/887, Batch Loss: 0.1507
Batch 472/887, Batch Loss: 0.1161
Batch 476/887, Batch Loss: 0.1070
Batch 480/887, Batch Loss: 0.0946
Batch 484/887, Batch Loss: 0.1308
Batch 488/887, Batch Loss: 0.1212
Batch 492/887, Batch Loss: 0.1255
Batch 496/887, Batch Loss: 0.1658
Batch 500/887, Batch Loss: 0.1322
Batch 504/887, Batch Loss: 0.1423
Batch 508/887, Batch Loss: 0.1557
Batch 512/887, Batch Loss: 0.1358
Batch 516/887, Batch Loss: 0.1563
Batch 520/887, Batch Loss: 0.1237
Batch 524/887, Batch Loss: 0.1311
Batch 528/887, Batch Loss: 0.1300
Batch 532/887, Batch Loss: 0.1529
Batch 536/887, Batch Loss: 0.1399
Batch 540/887, Batch Loss: 0.1107
Batch 544/887, Batch Loss: 0.1244
Batch 548/887, Batch Loss: 0.1281
Batch 552/887, Batch Loss: 0.1517
Batch 556/887, Batch Loss: 0.1104
Batch 560/887, Batch Loss: 0.1294
Batch 564/887, Batch Loss: 0.1377
Batch 568/887, Batch Loss: 0.1254
Batch 572/887, Batch Loss: 0.1394
Batch 576/887, Batch Loss: 0.1398
Batch 580/887, Batch Loss: 0.1248
Batch 584/887, Batch Loss: 0.1390
Batch 588/887, Batch Loss: 0.1381
Batch 592/887, Batch Loss: 0.1440
Batch 596/887, Batch Loss: 0.1236
Batch 600/887, Batch Loss: 0.1311
Batch 604/887, Batch Loss: 0.1226
Batch 608/887, Batch Loss: 0.1402
Batch 612/887, Batch Loss: 0.1177
Batch 616/887, Batch Loss: 0.1292
Batch 620/887, Batch Loss: 0.1345
Batch 624/887, Batch Loss: 0.1396
Batch 628/887, Batch Loss: 0.1446
Batch 632/887, Batch Loss: 0.1428
Batch 636/887, Batch Loss: 0.1703
Batch 640/887, Batch Loss: 0.1486
Batch 644/887, Batch Loss: 0.1310
Batch 648/887, Batch Loss: 0.1256
Batch 652/887, Batch Loss: 0.1507
Batch 656/887, Batch Loss: 0.1471
Batch 660/887, Batch Loss: 0.1329
Batch 664/887, Batch Loss: 0.1281
Batch 668/887, Batch Loss: 0.1406
Batch 672/887, Batch Loss: 0.1318
Batch 676/887, Batch Loss: 0.1209
Batch 680/887, Batch Loss: 0.1342
Batch 684/887, Batch Loss: 0.1217
Batch 688/887, Batch Loss: 0.1166
Batch 692/887, Batch Loss: 0.1262
Batch 696/887, Batch Loss: 0.1191
Batch 700/887, Batch Loss: 0.0943
Batch 704/887, Batch Loss: 0.1243
Batch 708/887, Batch Loss: 0.1184
Batch 712/887, Batch Loss: 0.0792
Batch 716/887, Batch Loss: 0.1339
Batch 720/887, Batch Loss: 0.1336
Batch 724/887, Batch Loss: 0.1573
Batch 728/887, Batch Loss: 0.1332
Batch 732/887, Batch Loss: 0.1108
Batch 736/887, Batch Loss: 0.1245
Batch 740/887, Batch Loss: 0.1119
Batch 744/887, Batch Loss: 0.1475
Batch 748/887, Batch Loss: 0.1278
Batch 752/887, Batch Loss: 0.1035
Batch 756/887, Batch Loss: 0.1109
Batch 760/887, Batch Loss: 0.1094
Batch 764/887, Batch Loss: 0.1077
Batch 768/887, Batch Loss: 0.1200
Batch 772/887, Batch Loss: 0.1109
Batch 776/887, Batch Loss: 0.1277
Batch 780/887, Batch Loss: 0.1722
Batch 784/887, Batch Loss: 0.1181
Batch 788/887, Batch Loss: 0.1300
Batch 792/887, Batch Loss: 0.1559
Batch 796/887, Batch Loss: 0.1735
Batch 800/887, Batch Loss: 0.1197
Batch 804/887, Batch Loss: 0.1500
Batch 808/887, Batch Loss: 0.1408
Batch 812/887, Batch Loss: 0.1498
Batch 816/887, Batch Loss: 0.1504
Batch 820/887, Batch Loss: 0.1317
Batch 824/887, Batch Loss: 0.1204
Batch 828/887, Batch Loss: 0.1261
Batch 832/887, Batch Loss: 0.1104
Batch 836/887, Batch Loss: 0.1225
Batch 840/887, Batch Loss: 0.1147
Batch 844/887, Batch Loss: 0.1514
Batch 848/887, Batch Loss: 0.1252
Batch 852/887, Batch Loss: 0.1356
Batch 856/887, Batch Loss: 0.1040
Batch 860/887, Batch Loss: 0.1163
Batch 864/887, Batch Loss: 0.1405
Batch 868/887, Batch Loss: 0.1093
Batch 872/887, Batch Loss: 0.1291
Batch 876/887, Batch Loss: 0.1144
Batch 880/887, Batch Loss: 0.1303
Batch 884/887, Batch Loss: 0.1949
Training Loss: 0.1296
Validation Metrics: {'accuracy': 0.8021553142481079, 'precision': 0.8298453139217471, 'recall': 0.2913738019169329, 'f1': 0.4313076377394183}
Epoch 3/3
Batch 4/887, Batch Loss: 0.1211
Batch 8/887, Batch Loss: 0.1285
Batch 12/887, Batch Loss: 0.1163
Batch 16/887, Batch Loss: 0.1043
Batch 20/887, Batch Loss: 0.1391
Batch 24/887, Batch Loss: 0.1181
Batch 28/887, Batch Loss: 0.1335
Batch 32/887, Batch Loss: 0.1363
Batch 36/887, Batch Loss: 0.1229
Batch 40/887, Batch Loss: 0.0847
Batch 44/887, Batch Loss: 0.0955
Batch 48/887, Batch Loss: 0.1521
Batch 52/887, Batch Loss: 0.1557
Batch 56/887, Batch Loss: 0.1210
Batch 60/887, Batch Loss: 0.0987
Batch 64/887, Batch Loss: 0.1345
Batch 68/887, Batch Loss: 0.1197
Batch 72/887, Batch Loss: 0.0978
Batch 76/887, Batch Loss: 0.1515
Batch 80/887, Batch Loss: 0.1013
Batch 84/887, Batch Loss: 0.1539
Batch 88/887, Batch Loss: 0.1329
Batch 92/887, Batch Loss: 0.1488
Batch 96/887, Batch Loss: 0.1383
Batch 100/887, Batch Loss: 0.1141
Batch 104/887, Batch Loss: 0.1122
Batch 108/887, Batch Loss: 0.1742
Batch 112/887, Batch Loss: 0.0906
Batch 116/887, Batch Loss: 0.1577
Batch 120/887, Batch Loss: 0.1184
Batch 124/887, Batch Loss: 0.1309
Batch 128/887, Batch Loss: 0.1477
Batch 132/887, Batch Loss: 0.1144
Batch 136/887, Batch Loss: 0.1101
Batch 140/887, Batch Loss: 0.1473
Batch 144/887, Batch Loss: 0.1289
Batch 148/887, Batch Loss: 0.1539
Batch 152/887, Batch Loss: 0.1366
Batch 156/887, Batch Loss: 0.1148
Batch 160/887, Batch Loss: 0.1266
Batch 164/887, Batch Loss: 0.1418
Batch 168/887, Batch Loss: 0.1254
Batch 172/887, Batch Loss: 0.1356
Batch 176/887, Batch Loss: 0.1027
Batch 180/887, Batch Loss: 0.1449
Batch 184/887, Batch Loss: 0.1154
Batch 188/887, Batch Loss: 0.1254
Batch 192/887, Batch Loss: 0.1270
Batch 196/887, Batch Loss: 0.1289
Batch 200/887, Batch Loss: 0.1146
Batch 204/887, Batch Loss: 0.1395
Batch 208/887, Batch Loss: 0.1423
Batch 212/887, Batch Loss: 0.1163
Batch 216/887, Batch Loss: 0.1158
Batch 220/887, Batch Loss: 0.1375
Batch 224/887, Batch Loss: 0.1478
Batch 228/887, Batch Loss: 0.1274
Batch 232/887, Batch Loss: 0.1121
Batch 236/887, Batch Loss: 0.0906
Batch 240/887, Batch Loss: 0.1081
Batch 244/887, Batch Loss: 0.1538
Batch 248/887, Batch Loss: 0.0788
Batch 252/887, Batch Loss: 0.1259
Batch 256/887, Batch Loss: 0.1491
Batch 260/887, Batch Loss: 0.1070
Batch 264/887, Batch Loss: 0.1136
Batch 268/887, Batch Loss: 0.0983
Batch 272/887, Batch Loss: 0.1149
Batch 276/887, Batch Loss: 0.0793
Batch 280/887, Batch Loss: 0.1336
Batch 284/887, Batch Loss: 0.1006
Batch 288/887, Batch Loss: 0.1299
Batch 292/887, Batch Loss: 0.1401
Batch 296/887, Batch Loss: 0.1525
Batch 300/887, Batch Loss: 0.1031
Batch 304/887, Batch Loss: 0.1487
Batch 308/887, Batch Loss: 0.1768
Batch 312/887, Batch Loss: 0.1501
Batch 316/887, Batch Loss: 0.1625
Batch 320/887, Batch Loss: 0.1653
Batch 324/887, Batch Loss: 0.1420
Batch 328/887, Batch Loss: 0.1154
Batch 332/887, Batch Loss: 0.1263
Batch 336/887, Batch Loss: 0.1253
Batch 340/887, Batch Loss: 0.1126
Batch 344/887, Batch Loss: 0.1147
Batch 348/887, Batch Loss: 0.0963
Batch 352/887, Batch Loss: 0.1347
Batch 356/887, Batch Loss: 0.1114
Batch 360/887, Batch Loss: 0.1420
Batch 364/887, Batch Loss: 0.1404
Batch 368/887, Batch Loss: 0.1778
Batch 372/887, Batch Loss: 0.1443
Batch 376/887, Batch Loss: 0.1543
Batch 380/887, Batch Loss: 0.1351
Batch 384/887, Batch Loss: 0.1588
Batch 388/887, Batch Loss: 0.1244
Batch 392/887, Batch Loss: 0.1246
Batch 396/887, Batch Loss: 0.1207
Batch 400/887, Batch Loss: 0.1391
Batch 404/887, Batch Loss: 0.1543
Batch 408/887, Batch Loss: 0.1232
Batch 412/887, Batch Loss: 0.1553
Batch 416/887, Batch Loss: 0.1369
Batch 420/887, Batch Loss: 0.1214
Batch 424/887, Batch Loss: 0.1279
Batch 428/887, Batch Loss: 0.1381
Batch 432/887, Batch Loss: 0.1212
Batch 436/887, Batch Loss: 0.1391
Batch 440/887, Batch Loss: 0.1744
Batch 444/887, Batch Loss: 0.1345
Batch 448/887, Batch Loss: 0.1291
Batch 452/887, Batch Loss: 0.1084
Batch 456/887, Batch Loss: 0.1211
Batch 460/887, Batch Loss: 0.1307
Batch 464/887, Batch Loss: 0.1315
Batch 468/887, Batch Loss: 0.1321
Batch 472/887, Batch Loss: 0.1009
Batch 476/887, Batch Loss: 0.1268
Batch 480/887, Batch Loss: 0.1195
Batch 484/887, Batch Loss: 0.1257
Batch 488/887, Batch Loss: 0.1367
Batch 492/887, Batch Loss: 0.1077
Batch 496/887, Batch Loss: 0.1614
Batch 500/887, Batch Loss: 0.1060
Batch 504/887, Batch Loss: 0.1413
Batch 508/887, Batch Loss: 0.1670
Batch 512/887, Batch Loss: 0.1615
Batch 516/887, Batch Loss: 0.1304
Batch 520/887, Batch Loss: 0.1206
Batch 524/887, Batch Loss: 0.1028
Batch 528/887, Batch Loss: 0.0938
Batch 532/887, Batch Loss: 0.1076
Batch 536/887, Batch Loss: 0.1417
Batch 540/887, Batch Loss: 0.1160
Batch 544/887, Batch Loss: 0.1140
Batch 548/887, Batch Loss: 0.1234
Batch 552/887, Batch Loss: 0.1400
Batch 556/887, Batch Loss: 0.1288
Batch 560/887, Batch Loss: 0.1266
Batch 564/887, Batch Loss: 0.1270
Batch 568/887, Batch Loss: 0.0775
Batch 572/887, Batch Loss: 0.1127
Batch 576/887, Batch Loss: 0.1037
Batch 580/887, Batch Loss: 0.0979
Batch 584/887, Batch Loss: 0.1443
Batch 588/887, Batch Loss: 0.1736
Batch 592/887, Batch Loss: 0.1491
Batch 596/887, Batch Loss: 0.1210
Batch 600/887, Batch Loss: 0.0969
Batch 604/887, Batch Loss: 0.1212
Batch 608/887, Batch Loss: 0.1242
Batch 612/887, Batch Loss: 0.1206
Batch 616/887, Batch Loss: 0.1246
Batch 620/887, Batch Loss: 0.1321
Batch 624/887, Batch Loss: 0.1379
Batch 628/887, Batch Loss: 0.1389
Batch 632/887, Batch Loss: 0.1123
Batch 636/887, Batch Loss: 0.1257
Batch 640/887, Batch Loss: 0.1287
Batch 644/887, Batch Loss: 0.0998
Batch 648/887, Batch Loss: 0.1301
Batch 652/887, Batch Loss: 0.1015
Batch 656/887, Batch Loss: 0.1085
Batch 660/887, Batch Loss: 0.1142
Batch 664/887, Batch Loss: 0.1169
Batch 668/887, Batch Loss: 0.1063
Batch 672/887, Batch Loss: 0.0915
Batch 676/887, Batch Loss: 0.1594
Batch 680/887, Batch Loss: 0.1125
Batch 684/887, Batch Loss: 0.0831
Batch 688/887, Batch Loss: 0.1293
Batch 692/887, Batch Loss: 0.1275
Batch 696/887, Batch Loss: 0.1255
Batch 700/887, Batch Loss: 0.1433
Batch 704/887, Batch Loss: 0.1880
Batch 708/887, Batch Loss: 0.1508
Batch 712/887, Batch Loss: 0.1122
Batch 716/887, Batch Loss: 0.1352
Batch 720/887, Batch Loss: 0.1151
Batch 724/887, Batch Loss: 0.1571
Batch 728/887, Batch Loss: 0.1112
Batch 732/887, Batch Loss: 0.1248
Batch 736/887, Batch Loss: 0.1258
Batch 740/887, Batch Loss: 0.1347
Batch 744/887, Batch Loss: 0.1698
Batch 748/887, Batch Loss: 0.1204
Batch 752/887, Batch Loss: 0.1277
Batch 756/887, Batch Loss: 0.1535
Batch 760/887, Batch Loss: 0.1143
Batch 764/887, Batch Loss: 0.1070
Batch 768/887, Batch Loss: 0.1101
Batch 772/887, Batch Loss: 0.1200
Batch 776/887, Batch Loss: 0.1264
Batch 780/887, Batch Loss: 0.1012
Batch 784/887, Batch Loss: 0.1123
Batch 788/887, Batch Loss: 0.1243
Batch 792/887, Batch Loss: 0.1095
Batch 796/887, Batch Loss: 0.1313
Batch 800/887, Batch Loss: 0.1204
Batch 804/887, Batch Loss: 0.1342
Batch 808/887, Batch Loss: 0.1221
Batch 812/887, Batch Loss: 0.1429
Batch 816/887, Batch Loss: 0.0963
Batch 820/887, Batch Loss: 0.1090
Batch 824/887, Batch Loss: 0.1006
Batch 828/887, Batch Loss: 0.1704
Batch 832/887, Batch Loss: 0.1069
Batch 836/887, Batch Loss: 0.1179
Batch 840/887, Batch Loss: 0.1407
Batch 844/887, Batch Loss: 0.1525
Batch 848/887, Batch Loss: 0.1303
Batch 852/887, Batch Loss: 0.1263
Batch 856/887, Batch Loss: 0.1273
Batch 860/887, Batch Loss: 0.1470
Batch 864/887, Batch Loss: 0.0945
Batch 868/887, Batch Loss: 0.1127
Batch 872/887, Batch Loss: 0.1352
Batch 876/887, Batch Loss: 0.1124
Batch 880/887, Batch Loss: 0.1389
Batch 884/887, Batch Loss: 0.1432
Training Loss: 0.1278
Validation Metrics: {'accuracy': 0.821076011846002, 'precision': 0.7847346451997614, 'recall': 0.4204472843450479, 'f1': 0.5475348450176826}
Job completed
