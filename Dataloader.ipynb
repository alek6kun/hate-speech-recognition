{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "######################## call me sexist ###########################\n",
    "# Function to clean text by removing <\"MENTION\" numbers>, hashtags, URLs, and \"RT\"\n",
    "def clean_text(text):\n",
    "    # Remove <\"MENTION\" numbers>\n",
    "    text = re.sub(r'\\bMENTION\\d+\\b', '', text)\n",
    "    # Remove hashtags (e.g., #something)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    # Remove URLs (e.g., http:/something)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove \"RT\"\n",
    "    text = re.sub(r'\\bRT\\b', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "input_file = 'Call_me_sexist_but_dataset_reduced.csv'  # replace with your actual file name\n",
    "df = pd.read_csv(input_file, header=None, names=['text', 'label'])\n",
    "\n",
    "# Apply the clean_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Remove empty rows\n",
    "df = df[df['text'].astype(bool)]\n",
    "\n",
    "# Save the cleaned data back to a new CSV file\n",
    "output_file = 'cleaned_Call_me_sexist_but_dataset_reduced.csv'  # replace with your desired output file name\n",
    "df.to_csv(output_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "###################### offensive statemenets (German) ########################3\n",
    "# Function to clean text by removing hex IDs, replacing with \"Peter\", and removing URLs\n",
    "def clean_text(text):\n",
    "    # Replace hex IDs with \"Peter\"\n",
    "    text = re.sub(r'\\b[a-fA-F0-9]{16}\\b', 'Peter', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "input_file = 'Detecting_Offensive_Statements_towards_Foreigners_in_Social_Media_reduced.csv'  # replace with your actual file name\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_file, header=None, names=['text', 'label'], sep=',', encoding='utf-8', on_bad_lines='skip', engine='python')\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error parsing CSV file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Apply the clean_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Remove empty rows\n",
    "df = df[df['text'].astype(bool)]\n",
    "\n",
    "# Save the cleaned data back to a new CSV file\n",
    "output_file = 'cleaned_Detecting_Offensive_Statements_towards_Foreigners_in_Social_Media_reduced.csv'  # replace with your desired output file name\n",
    "df.to_csv(output_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "########################## misoginy ##########################\n",
    "# Function to clean text by removing URLs, short lines, lines starting with '>', and lines containing '[deleted]' or '[removed]'\n",
    "def clean_text(text):\n",
    "    # Convert non-string values to empty string\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove lines starting with '>'\n",
    "    text = re.sub(r'^>', '', text, flags=re.MULTILINE)\n",
    "    # Remove lines containing '[deleted]' or '[removed]'\n",
    "    text = re.sub(r'\\[deleted\\]|\\[removed\\]', '', text)\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "input_file = 'online-misoginy-eacl2021_reduced.csv'  # replace with your actual file name\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_file, header=None, names=['text', 'label'], sep=',', encoding='utf-8', engine='python')\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error parsing CSV file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Apply the clean_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df = df[df['text'].str.len() >= 5]\n",
    "\n",
    "# Save the cleaned data back to a new CSV file\n",
    "output_file = 'cleaned_online-misoginy-eacl2021_reduced.csv'  # replace with your desired output file name\n",
    "df.to_csv(output_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#################### TOXYGEN #################\n",
    "# Function to clean text by removing unwanted patterns\n",
    "def clean_text(text):\n",
    "    # Remove 'b\" ... \"' and '\\n-'\n",
    "    text = re.sub(r'b\\\"\\\"|\\\\n-', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove repetitions of more than 3 of the same character\n",
    "    text = re.sub(r'(\\w)\\1{3,}', r'\\1\\1\\1', text)\n",
    "    # Remove anything within square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "input_file = 'data_toxygen.csv'  # replace with your actual file name\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_file, header=None, names=['text', 'label'], sep=',', encoding='utf-8', engine='python')\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"Error parsing CSV file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Apply the clean_text function to the 'text' column\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df = df[df['text'].str.len() >= 5]\n",
    "\n",
    "# Save the cleaned data back to a new CSV file\n",
    "output_file = 'cleaned_data_toxygen.csv'  # replace with your desired output file name\n",
    "df.to_csv(output_file, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values in the 'text' column are strings.\n",
      "All values in the 'label' column are integers.\n",
      "Cleaned DataFrame saved to /Users/ninabodenstab/Desktop/University/EPFL/Ma2/Deep Learning/Projet/cleaned_dataset3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#This function tests if all instances in the \"label\" column are integers and if all instance in the \"text\" column are strings. It also removes rows where there are instances of \n",
    "# \"label\". Also, if there are floats or object types in the \"labels\" column, it transforms them into integers. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def check_csv_types(csv_file, output_file):\n",
    "    # Read the CSV file into a pandas DataFrame, skipping the first row\n",
    "    df = pd.read_csv(csv_file, skiprows=0)\n",
    "    \n",
    "    # Check if the first column contains only strings\n",
    "    if 'text' in df.columns:\n",
    "        text_dtype = df['text'].dtype\n",
    "        if text_dtype == 'object':\n",
    "            print(\"All values in the 'text' column are strings.\")\n",
    "        else:\n",
    "            print(f\"The 'text' column contains non-string values of type {text_dtype}.\")\n",
    "    else:\n",
    "        print(\"The 'text' column is not found in the DataFrame.\")\n",
    "    \n",
    "    # Check and clean the 'label' column\n",
    "    if 'label' in df.columns:\n",
    "        df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
    "        df = df.dropna(subset=['label'])  # Remove rows with NaN in the 'label' column\n",
    "        \n",
    "        # Convert floats to integers\n",
    "        df['label'] = df['label'].astype(int)\n",
    "        \n",
    "        labels_dtype = df['label'].dtype\n",
    "        if labels_dtype == 'int64':\n",
    "            print(\"All values in the 'label' column are integers.\")\n",
    "        else:\n",
    "            print(f\"The 'label' column contains non-integer values of type {labels_dtype}.\")\n",
    "            print(\"Non-integer values in 'label' column:\", df['label'].unique())\n",
    "    else:\n",
    "        print(\"The 'label' column is not found in the DataFrame.\")\n",
    "    \n",
    "    # Save the cleaned DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Cleaned DataFrame saved to {output_file}\")\n",
    "\n",
    "# Replace 'combined_dataset1.csv' with the path to your CSV file\n",
    "# Replace 'cleaned_dataset1.csv' with the desired name of the output file\n",
    "check_csv_types('combined_dataset1.csv', '/Users/ninabodenstab/Desktop/University/EPFL/Ma2/Deep Learning/Projet/cleaned_dataset3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
